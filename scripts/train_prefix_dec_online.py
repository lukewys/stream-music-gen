"""Training of encoder decoder model."""

import os

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

# Disable compile
# os.environ["TORCH_COMPILE_DISABLE"] = "1"

import torch
import torch.multiprocessing

torch.multiprocessing.set_sharing_strategy("file_system")
torch._dynamo.config.disable = True

import resource

rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)
resource.setrlimit(resource.RLIMIT_NOFILE, (4096, rlimit[1]))

import argbind

from functools import partial
from pathlib import Path

from stream_music_gen.base_trainer import Trainer
from stream_music_gen.lit_module.online_prefix_dec import (
    LitOnlinePrefixDecoderMultiOut,
)

GROUP = __file__
# Binding things only when this file is loaded
bind = partial(argbind.bind, group=GROUP)

Trainer = bind(Trainer, without_prefix=True)


@bind(without_prefix=True)
def main(args, save_dir: str = ""):

    # Create the lit module
    lit_module = LitOnlinePrefixDecoderMultiOut()  # Modified - Delay Pattern

    # Get the dataloaders
    train_dataloader, val_dataloader = lit_module.get_dataloaders()

    # Train the model
    trainer = Trainer(
        args=args,
        lit_module=lit_module,
        save_dir=save_dir,
        train_dataloader=train_dataloader,
        val_dataloader=val_dataloader,
    )
    trainer.train()


if __name__ == "__main__":
    args = argbind.parse_args(group=GROUP)
    argbind.dump_args(args, Path(args["save_dir"]) / "args.yml")
    with argbind.scope(args):
        main(args)
